Every day, we're bombarded with statistics on economics, politics, science, etc. But too often, numbers go in one eye and out the other. So the question is:

**How do you make statistics more sticky?**

Take a wild guess on these three stats:

// interactive

This guessing game was part of [a randomized controlled web-experiment]() I did earlier this month. Inspired by New York Times' [You Draw It](), I wanted to see if predicting a statistic *before* seeing it makes it more memorable.

Here was my experimental design:

![](design.png)

Both groups see 10 statistics about the world, in random order. Why 10? Because I wanted to overload short-term memory, which cognitive scientists have estimated can only hold 7±2 "chunks".* (Or maybe 3±1*)

Previous studies have already shown that confronting your misconceptions helps you learn better, whether that's directly[muller] or indirectly through prediction[crouch, hullman]. So, [when I "pre-registered" my experiment](), I hypothesized that "predict it first" should create a *small* increase in memory retention.

But when I analyzed the data (N=1000+ responses), to my great surprise...

Well... what do *you* predict happened?

// interactive

That's right: *null result.*

(sad trombone)

So after performing the scientific protocol of "moping around for a few days", I embraced the null. Because, this null *was* puzzling. People in the experimental "predict it first" group reported *liking* the content more (d=0.55, p<0.001), and reported being *surprised* more (d=0.51, p<0.001)... **and yet that's *still not sufficient* for helping people *remember* more.**[animation study]

![](metrics1.png)

![](metrics2.png)

Therefore, my experiment (with its null result) must have had something different from all the previous "confront your misconceptions first" experiments (with their positive results)[crouch, huller, muller].

I think the big difference was this: **all the other studies taught & tested people on ONE topic.** Whether that's quantum mechanics, voter demographics, smartphone prices – they showed information on a single topic, and never mixed topics.

In contrast, my experiment showed *10 different stats in 10 different topics* in five minutes. I think I got exactly what I wished for: I overloaded short-term memory. If "predict it first" had any effect, it would have been wiped out by the sheer cognitive load of trying to hold 10 unrelated facts in one's head.

![](splash.png)

In hindsight, that sounds like an obvious mistake, but "cram lots of ideas in a short time" *is what a lot of online educational content does.* Top 10 Lists, lightning-pace YouTube videos, etc. My null result implies a hard lesson for "educational content" makers: **no matter how interesting or surprising you make your content, if you go against basic cognitive science principles, it'll all be for naught.**

I've been making "interactive explainers" for years. I think it'd be good for me to keep doing these (admittedly amateur) cognitive science experiments. Practice without theory can get lost down a blind alley, theory without practice can get lost in the clouds. Maybe by doing both, I can help the two fields learn from each other.

That's my hypothesis, anyway.

It's time to test that.

---

Special thanks to my Patreon supporters for helping me do this experiment! (See their names & drawings here) (Help me make more games/science)

Also huge thanks to these folks for giving design/science advice: [ee] [srini] [jessica hullman]

Play the experiment here: random | control | experiment

My data: raw (zip) | cleaned (csv)

My data-cleaning code: jupyter | html export

My data-analysis code: jupyter | html export

Experiment source code: github

---

Footnotes & References: